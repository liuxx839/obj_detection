import streamlit as st
from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import io
import os
import pickle
import uuid
import time
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
import faiss
import torch
from torchvision import models, transforms
from groq import Groq
from openai import OpenAI
import base64
from io import BytesIO
from mtcnn import MTCNN
from deepface import DeepFace



# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="ç‰©ä½“æ£€æµ‹ä¸ç›¸ä¼¼æœç´¢å·¥å…·", layout="wide")

# åˆå§‹åŒ–session_stateä»¥è·Ÿè¸ªå›¾ç‰‡å¤„ç†çŠ¶æ€
if 'processed' not in st.session_state:
    st.session_state.processed = False
if 'image' not in st.session_state:
    st.session_state.image = None
if 'last_upload_id' not in st.session_state:
    st.session_state.last_upload_id = None
if 'detection_results' not in st.session_state:
    st.session_state.detection_results = None
if 'processed_img' not in st.session_state:
    st.session_state.processed_img = None
if 'detected_faces' not in st.session_state:
    st.session_state.detected_faces = []
if 'similar_images' not in st.session_state:
    st.session_state.similar_images = []
if 'similar_faces_results' not in st.session_state:
    st.session_state.similar_faces_results = []

# æ ‡é¢˜
st.title("ğŸ“· é«˜ç²¾åº¦ç‰©ä½“æ£€æµ‹ä¸ç›¸ä¼¼æœç´¢å·¥å…·")
st.write("ä¸Šä¼ å›¾ç‰‡ï¼Œæ£€æµ‹äººã€é…’æ¯ç­‰ç‰©ä½“ï¼Œå¹¶åœ¨å†å²å›¾ç‰‡ä¸­å¯»æ‰¾ç›¸ä¼¼å›¾ç‰‡å’Œäººè„¸")

# åˆ›å»ºå­˜å‚¨ç›®å½•
def create_directories():
    dirs = ["data", "data/images", "data/faces", "data/vectors"]
    for dir_path in dirs:
        os.makedirs(dir_path, exist_ok=True)
    return Path("data")

data_dir = create_directories()

# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    st.header("è®¾ç½®")
    
    # æ¨¡å‹é€‰æ‹©
    model_option = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        ["YOLOv11x (æœ€é«˜ç²¾åº¦ï¼Œè¾ƒæ…¢)", 
         "YOLOv11l (é«˜ç²¾åº¦)", 
         "YOLOv11m (ä¸­ç­‰ç²¾åº¦)", 
         "YOLOv11s (è¾ƒå¿«)", 
         "YOLOv11n (æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½)",
         "YOLOv8x (æœ€é«˜ç²¾åº¦ï¼Œè¾ƒæ…¢)", 
         "YOLOv8l (é«˜ç²¾åº¦)", 
         "YOLOv8m (ä¸­ç­‰ç²¾åº¦)", 
         "YOLOv8s (è¾ƒå¿«)", 
         "YOLOv8n (æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½)"],
        index=4  # é»˜è®¤é€‰æ‹©YOLOv11x
    )
    
    # æ¨¡å‹æ˜ å°„
    model_mapping = {
        "YOLOv11x (æœ€é«˜ç²¾åº¦ï¼Œè¾ƒæ…¢)": "yolo11x.pt",
        "YOLOv11l (é«˜ç²¾åº¦)": "yolo11l.pt",
        "YOLOv11m (ä¸­ç­‰ç²¾åº¦)": "yolo11m.pt",
        "YOLOv11s (è¾ƒå¿«)": "yolo11s.pt",
        "YOLOv11n (æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½)": "yolo11n.pt",
        "YOLOv8x (æœ€é«˜ç²¾åº¦ï¼Œè¾ƒæ…¢)": "yolov8x.pt",
        "YOLOv8l (é«˜ç²¾åº¦)": "yolov8l.pt",
        "YOLOv8m (ä¸­ç­‰ç²¾åº¦)": "yolov8m.pt",
        "YOLOv8s (è¾ƒå¿«)": "yolov8s.pt",
        "YOLOv8n (æœ€å¿«ï¼Œç²¾åº¦è¾ƒä½)": "yolov8n.pt"
    }
    
    confidence = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.1, 1.0, 0.5, 0.1)
    
    # é€‰æ‹©è¦æ£€æµ‹çš„ç±»åˆ«
    st.subheader("é€‰æ‹©è¦æ£€æµ‹çš„ç±»åˆ«")
    detect_person = st.checkbox("äºº", value=True)
    detect_cup = st.checkbox("æ¯å­/é…’æ¯", value=True)
    detect_bottle = st.checkbox("ç“¶å­", value=True)
    detect_all = st.checkbox("æ£€æµ‹æ‰€æœ‰æ”¯æŒçš„ç‰©ä½“", value=True)
    
    # äººè„¸æ£€æµ‹é€‰é¡¹
    st.subheader("äººè„¸æ£€æµ‹")
    detect_faces = st.checkbox("å¯ç”¨äººè„¸æ£€æµ‹", value=True)
    face_confidence = st.slider("äººè„¸æ£€æµ‹ç½®ä¿¡åº¦", 0.1, 1.0, 0.8, 0.1)
    
    # ç›¸ä¼¼æœç´¢é€‰é¡¹
    st.subheader("ç›¸ä¼¼æœç´¢")
    enable_similarity_search = st.checkbox("å¯ç”¨ç›¸ä¼¼å›¾ç‰‡æœç´¢", value=True)
    enable_face_similarity = st.checkbox("å¯ç”¨äººè„¸ç›¸ä¼¼æœç´¢", value=True)
    similarity_threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.0, 1.0, 0.8, 0.05)
    top_k = st.slider("è¿”å›ç›¸ä¼¼ç»“æœæ•°é‡", 1, 10, 3)
    
    # è·å–é¢œè‰²è®¾ç½®
    st.subheader("æ ‡è®°é¢œè‰²")
    box_color = st.color_picker("è¾¹æ¡†é¢œè‰²", "#FF0000")
    face_box_color = st.color_picker("äººè„¸è¾¹æ¡†é¢œè‰²", "#00FF00")

# åŠ è½½YOLOæ¨¡å‹
@st.cache_resource
def load_model(model_name):
    return YOLO(model_name)

# åŠ è½½äººè„¸æ£€æµ‹æ¨¡å‹
@st.cache_resource
def load_face_detector():
    # ä½¿ç”¨MTCNNäººè„¸æ£€æµ‹å™¨
    detector = MTCNN()
    return detector


# åŠ è½½ç‰¹å¾æå–æ¨¡å‹
@st.cache_resource
def load_feature_extractor():
    # ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet50
    model = models.resnet50(weights='DEFAULT')
    # ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚
    model = torch.nn.Sequential(*(list(model.children())[:-1]))
    model.eval()
    return model

# å›¾åƒé¢„å¤„ç†è½¬æ¢
@st.cache_resource
def get_transform():
    return transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

# æå–å›¾åƒç‰¹å¾
def extract_image_features(image, model, transform):
    # é¢„å¤„ç†å›¾åƒ
    img_t = transform(image).unsqueeze(0)
    
    # æå–ç‰¹å¾
    with torch.no_grad():
        features = model(img_t)
    
    # è¿”å›ç‰¹å¾å‘é‡
    return features.squeeze().cpu().numpy()

# æå–äººè„¸ç‰¹å¾
def extract_face_features(face_image, model, transform):
    # å¦‚æœäººè„¸å›¾åƒå¤ªå°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å¤§å°
    if face_image.size[0] < 30 or face_image.size[1] < 30:
        return None
    
    # é¢„å¤„ç†äººè„¸å›¾åƒ
    face_t = transform(face_image).unsqueeze(0)
    
    # æå–ç‰¹å¾
    with torch.no_grad():
        features = model(face_t)
    
    # è¿”å›ç‰¹å¾å‘é‡
    return features.squeeze().cpu().numpy()

# åˆå§‹åŒ–å‘é‡åº“
def initialize_vector_db():
    vector_file = data_dir / "vectors" / "image_vectors.pkl"
    face_vector_file = data_dir / "vectors" / "face_vectors.pkl"
    
    # å›¾åƒå‘é‡æ•°æ®åº“
    if os.path.exists(vector_file):
        with open(vector_file, 'rb') as f:
            image_db = pickle.load(f)
    else:
        # åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“
        # ä½¿ç”¨å­—å…¸å­˜å‚¨: {image_id: {'vector': feature_vector, 'path': image_path}}
        image_db = {}
    
    # äººè„¸å‘é‡æ•°æ®åº“
    if os.path.exists(face_vector_file):
        with open(face_vector_file, 'rb') as f:
            face_db = pickle.load(f)
    else:
        # åˆ›å»ºæ–°çš„äººè„¸å‘é‡æ•°æ®åº“
        # ä½¿ç”¨å­—å…¸å­˜å‚¨: {face_id: {'vector': feature_vector, 'path': face_path, 'image_id': parent_image_id}}
        face_db = {}
    
    return image_db, face_db

# ä¿å­˜å‘é‡æ•°æ®åº“
def save_vector_db(image_db, face_db):
    vector_file = data_dir / "vectors" / "image_vectors.pkl"
    face_vector_file = data_dir / "vectors" / "face_vectors.pkl"
    
    with open(vector_file, 'wb') as f:
        pickle.dump(image_db, f)
    
    with open(face_vector_file, 'wb') as f:
        pickle.dump(face_db, f)

# æ›´æ–°å‘é‡æ•°æ®åº“
def update_vector_db(image, faces, feature_extractor, transform):
    # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    image_db, face_db = initialize_vector_db()
    
    # ç”Ÿæˆå”¯ä¸€ID
    image_id = str(uuid.uuid4())
    timestamp = int(time.time())
    
    # ä¿å­˜å›¾åƒ
    image_filename = f"{image_id}.jpg"
    image_path = data_dir / "images" / image_filename
    # ç¡®ä¿å›¾åƒä¸ºRGBæ¨¡å¼
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    image.save(image_path)
    
    # æå–å›¾åƒç‰¹å¾
    image_features = extract_image_features(image, feature_extractor, transform)
    
    # æ›´æ–°å›¾åƒå‘é‡æ•°æ®åº“
    image_db[image_id] = {
        'vector': image_features,
        'path': str(image_path),
        'timestamp': timestamp
    }
    
    # å¤„ç†äººè„¸
    face_ids = []
    for i, face in enumerate(faces):
        face_id = f"{image_id}_face_{i}"
        face_filename = f"{face_id}.jpg"
        face_path = data_dir / "faces" / face_filename
        
        # å°†PIL Imageè½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ä¿å­˜
        face_pil = Image.fromarray(face)
        # ç¡®ä¿äººè„¸å›¾åƒä¸ºRGBæ¨¡å¼
        if face_pil.mode == 'RGBA':
            face_pil = face_pil.convert('RGB')
        face_pil.save(face_path)
        
        # æå–äººè„¸ç‰¹å¾
        face_features = extract_face_features(face_pil, feature_extractor, transform)
        
        if face_features is not None:
            # æ›´æ–°äººè„¸å‘é‡æ•°æ®åº“
            face_db[face_id] = {
                'vector': face_features,
                'path': str(face_path),
                'image_id': image_id,
                'timestamp': timestamp
            }
            face_ids.append(face_id)
    
    # ä¿å­˜æ›´æ–°åçš„å‘é‡æ•°æ®åº“
    save_vector_db(image_db, face_db)
    
    return image_id, face_ids

# æ‰§è¡Œç›¸ä¼¼æœç´¢
def search_similar_images(query_vector, image_db, top_k=3, threshold=0.6):
    if not image_db:
        return []
    
    results = []
    
    # è®¡ç®—æŸ¥è¯¢å‘é‡ä¸æ•°æ®åº“ä¸­æ‰€æœ‰å‘é‡çš„ç›¸ä¼¼åº¦
    for image_id, data in image_db.items():
        db_vector = data['vector']
        similarity = cosine_similarity([query_vector], [db_vector])[0][0]
        
        if similarity >= threshold:
            results.append({
                'id': image_id,
                'path': data['path'],
                'similarity': similarity,
                'timestamp': data.get('timestamp', 0)
            })
    
    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
    results.sort(key=lambda x: x['similarity'], reverse=True)
    
    # è¿”å›å‰Kä¸ªç»“æœ
    return results[:top_k]

# æ‰§è¡Œäººè„¸ç›¸ä¼¼æœç´¢
def search_similar_faces(query_vectors, face_db, top_k=3, threshold=0.6):
    if not face_db or not query_vectors:
        return []
    
    all_results = []
    
    # å¯¹æ¯ä¸ªæŸ¥è¯¢äººè„¸è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
    for i, query_vector in enumerate(query_vectors):
        results = []
        
        # è®¡ç®—æŸ¥è¯¢å‘é‡ä¸æ•°æ®åº“ä¸­æ‰€æœ‰äººè„¸å‘é‡çš„ç›¸ä¼¼åº¦
        for face_id, data in face_db.items():
            db_vector = data['vector']
            similarity = cosine_similarity([query_vector], [db_vector])[0][0]
            
            if similarity >= threshold:
                results.append({
                    'id': face_id,
                    'path': data['path'],
                    'image_id': data['image_id'],
                    'similarity': similarity,
                    'timestamp': data.get('timestamp', 0)
                })
        
        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        results.sort(key=lambda x: x['similarity'], reverse=True)
        
        # ä¸ºå½“å‰æŸ¥è¯¢äººè„¸ä¿å­˜å‰Kä¸ªç»“æœ
        all_results.append({
            'query_face_index': i,
            'matches': results[:top_k]
        })
    
    return all_results

# å¤„ç†é¢„æµ‹ç»“æœå¹¶ç»˜åˆ¶è¾¹æ¡†
def process_prediction(image, results, selected_classes, conf_threshold):
    # è½¬æ¢ä¸ºOpenCVæ ¼å¼ç”¨äºç»˜å›¾
    img = np.array(image)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    
    # COCOæ•°æ®é›†ç±»åˆ«
    class_names = results[0].names
    
    # å¦‚æœé€‰æ‹©äº†"æ£€æµ‹æ‰€æœ‰æ”¯æŒçš„ç‰©ä½“"ï¼Œå°†æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«
    if "æ£€æµ‹æ‰€æœ‰æ”¯æŒçš„ç‰©ä½“" in selected_classes:
        selected_class_ids = list(class_names.keys())
    else:
        # åˆ›å»ºç±»åˆ«åç§°åˆ°IDçš„æ˜ å°„
        class_mapping = {
            "äºº": 0,  # person
            "æ¯å­/é…’æ¯": 41,  # cup
            "ç“¶å­": 39,  # bottle
        }
        # è·å–é€‰ä¸­ç±»åˆ«çš„ID
        selected_class_ids = [class_mapping[cls] for cls in selected_classes if cls in class_mapping]
    
    # è§£æåå…­è¿›åˆ¶é¢œè‰²ä¸ºBGR
    hex_color = box_color.lstrip('#')
    box_bgr = tuple(int(hex_color[i:i+2], 16) for i in (4, 2, 0))  # è½¬æ¢ä¸ºBGR
    
    # å¦‚æœæœ‰æ£€æµ‹ç»“æœ
    if results[0].boxes is not None:
        boxes = results[0].boxes
        
        for box in boxes:
            # è·å–ç±»åˆ«IDå’Œç½®ä¿¡åº¦
            cls_id = int(box.cls.item())
            conf = box.conf.item()
            
            # å¦‚æœç±»åˆ«åœ¨é€‰ä¸­çš„ç±»åˆ«ä¸­ä¸”ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼
            if cls_id in selected_class_ids and conf >= conf_threshold:
                # è·å–è¾¹ç•Œæ¡†åæ ‡
                x1, y1, x2, y2 = box.xyxy[0].tolist()
                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(img, (x1, y1), (x2, y2), box_bgr, 2)
                
                # æ·»åŠ æ ‡ç­¾
                label = f"{class_names[cls_id]} {conf:.2f}"
                text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                cv2.rectangle(img, (x1, y1 - text_size[1] - 5), (x1 + text_size[0], y1), box_bgr, -1)
                cv2.putText(img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    # è½¬æ¢å›RGBç”¨äºStreamlitæ˜¾ç¤º
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img

# äººè„¸æ£€æµ‹å‡½æ•°
def detect_face(image, face_detector, conf_threshold):
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    img = np.array(image)
    img_rgb = img.copy()
    
    # ä½¿ç”¨MTCNNæ£€æµ‹äººè„¸
    faces = face_detector.detect_faces(img_rgb)
    
    # ç­›é€‰ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼çš„äººè„¸
    faces = [face for face in faces if face['confidence'] >= conf_threshold]
    
    # è§£æäººè„¸è¾¹æ¡†é¢œè‰²
    hex_color = face_box_color.lstrip('#')
    face_bgr = tuple(int(hex_color[i:i+2], 16) for i in (4, 2, 0))  # è½¬æ¢ä¸ºBGR
    
    # æå–çš„äººè„¸å›¾åƒåˆ—è¡¨
    face_images = []
    
    # åœ¨åŸå›¾ä¸Šæ ‡è®°äººè„¸
    img_cv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    for face in faces:
        # è·å–è¾¹ç•Œæ¡†åæ ‡
        x, y, w, h = face['box']
        
        # ç»˜åˆ¶äººè„¸è¾¹æ¡†
        cv2.rectangle(img_cv, (x, y), (x+w, y+h), face_bgr, 2)
        
        # æ·»åŠ æ ‡ç­¾å’Œç½®ä¿¡åº¦
        label = f"Face: {face['confidence']:.2f}"
        cv2.putText(img_cv, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, face_bgr, 2)
        
        # å¯é€‰ï¼šç»˜åˆ¶å…³é”®ç‚¹
        keypoints = face['keypoints']
        for point in keypoints.values():
            cv2.circle(img_cv, point, 2, face_bgr, 2)
        
        # æå–äººè„¸åŒºåŸŸ
        face_crop = img_rgb[y:y+h, x:x+w]
        face_images.append(face_crop)
    
    # è½¬æ¢å›RGB
    result_img = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
    
    return result_img, face_images 

# æ˜¾ç¤ºç›¸ä¼¼å›¾ç‰‡ç»“æœ
def display_similar_images(similar_images):
    if not similar_images:
        st.info("æœªæ‰¾åˆ°ç›¸ä¼¼å›¾ç‰‡")
        return
    
    st.subheader(f"ç›¸ä¼¼å›¾ç‰‡æ£€ç´¢ç»“æœ (Top {len(similar_images)})")
    
    # æ˜¾ç¤ºç»“æœ
    cols = st.columns(min(len(similar_images), 3))
    for i, result in enumerate(similar_images):
        with cols[i % 3]:
            image_path = Path(result['path'])
            if image_path.exists():
                img = Image.open(image_path)
                st.image(img, caption=f"ç›¸ä¼¼åº¦: {result['similarity']:.2f}", use_container_width=True)
                
                # æ˜¾ç¤ºæ—¶é—´æˆ³ï¼ˆè½¬æ¢ä¸ºå¯è¯»æ ¼å¼ï¼‰
                if 'timestamp' in result:
                    time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(result['timestamp']))
                    st.caption(f"ä¸Šä¼ æ—¶é—´: {time_str}")

# æ˜¾ç¤ºç›¸ä¼¼äººè„¸ç»“æœ
def display_similar_faces(similar_faces_results, detected_faces):
    if not similar_faces_results:
        st.info("æœªæ‰¾åˆ°ç›¸ä¼¼äººè„¸")
        return
    
    st.subheader("äººè„¸ç›¸ä¼¼åº¦æ£€ç´¢ç»“æœ")
    
    # ä¸ºæ¯ä¸ªæŸ¥è¯¢äººè„¸æ˜¾ç¤ºå…¶åŒ¹é…ç»“æœ
    for result in similar_faces_results:
        query_face_idx = result['query_face_index']
        matches = result['matches']
        
        if matches:
            st.write(f"##### æŸ¥è¯¢äººè„¸ #{query_face_idx + 1} çš„åŒ¹é…ç»“æœ:")
            
            # æ˜¾ç¤ºæŸ¥è¯¢äººè„¸
            query_face = detected_faces[query_face_idx]
            query_face_pil = Image.fromarray(query_face)
            
            # åˆ›å»ºåˆ—æ¥æ˜¾ç¤ºæŸ¥è¯¢äººè„¸å’ŒåŒ¹é…ç»“æœ
            cols = st.columns(1 + min(len(matches), 3))
            
            # æ˜¾ç¤ºæŸ¥è¯¢äººè„¸
            with cols[0]:
                st.image(query_face_pil, caption="æŸ¥è¯¢äººè„¸", use_container_width=True)
            
            # æ˜¾ç¤ºåŒ¹é…ç»“æœ
            for i, match in enumerate(matches):
                if i < len(cols) - 1:  # ç¡®ä¿ä¸è¶…å‡ºåˆ—æ•°
                    with cols[i + 1]:
                        face_path = Path(match['path'])
                        if face_path.exists():
                            match_face = Image.open(face_path)
                            st.image(match_face, caption=f"ç›¸ä¼¼åº¦: {match['similarity']:.2f}", use_container_width=True)
                            
                            # æ˜¾ç¤ºæ—¶é—´æˆ³ï¼ˆè½¬æ¢ä¸ºå¯è¯»æ ¼å¼ï¼‰
                            if 'timestamp' in match:
                                time_str = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(match['timestamp']))
                                st.caption(f"ä¸Šä¼ æ—¶é—´: {time_str}")

# æ·»åŠ ä¸€ä¸ªæ¸…é™¤å¤„ç†çŠ¶æ€çš„å‡½æ•°
def reset_processed_state():
    st.session_state.processed = False
    st.session_state.detection_results = None
    st.session_state.processed_img = None
    st.session_state.detected_faces = []
    st.session_state.similar_images = []
    st.session_state.similar_faces_results = []

# ä¿®æ”¹å›¾ç‰‡è½¬base64å‡½æ•°
def image_to_base64(image):
    # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼
    if image.mode in ('RGBA', 'P'):
        image = image.convert('RGB')
    
    buffered = BytesIO()
    image.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode()

# ä¿®æ”¹analyze_with_groqå‡½æ•°
def analyze_with_groq(image, api_key):
    client_vision = Groq()
    client_vision.api_key = api_key
    
    try:
        # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ¨¡å¼
        if image.mode in ('RGBA', 'P'):
            image = image.convert('RGB')
            
        base64_image = image_to_base64(image)
        
        response = client_vision.chat.completions.create(
            model="meta-llama/llama-4-scout-17b-16e-instruct",
            messages=[
                {
                    "role": "system",
                    "content": '''è¯·æŒ‰ä»¥ä¸‹è§„åˆ™åˆ†æå›¾ç‰‡å†…å®¹ï¼š
                    é¦–å…ˆåˆ¤æ–­å›¾ç‰‡ä¸»è¦å†…å®¹æ˜¯å¦ä¸ºæ–‡å­—å†…å®¹ï¼ˆå³å›¾ç‰‡ä¸­è¶…è¿‡ 50% çš„åŒºåŸŸä¸ºå¯è¯†åˆ«çš„æ–‡å­—ï¼Œå¦‚æ–‡æ¡£ã€æµ·æŠ¥ã€æ ‡è¯­ç­‰ï¼‰ï¼š
                    è‹¥æ˜¯ï¼šç›´æ¥æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰å¯è¯†åˆ«æ–‡å­—ï¼ˆæ— éœ€é¢å¤–æè¿°ï¼‰ã€‚
                    è‹¥å¦ï¼šè¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹ï¼Œéœ€åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼ˆæ— ç›¸å…³ä¿¡æ¯åˆ™æ ‡æ³¨ "æœªæåŠ" æˆ– "æ— æ³•åˆ¤æ–­"ï¼‰ï¼š
                    â–ªï¸ ä¸»ä½“å†…å®¹ï¼šæ¸…æ™°æè¿°ç”»é¢ä¸­çš„ç‰©ä½“ã€åœºæ™¯ã€åŠ¨ä½œç­‰ç»†èŠ‚ï¼ˆå¦‚ "å®¤å†…ä¼šè®®åœºæ™¯ï¼Œ3 äººå›´åè®¨è®ºï¼Œæ¡Œä¸Šæ‘†æ”¾ç¬”è®°æœ¬ç”µè„‘å’Œæ–‡ä»¶"ï¼‰ã€‚
                    â–ªï¸ äººç‰©ä¿¡æ¯ï¼ˆè‹¥åŒ…å«äººï¼‰ï¼š
                    ãƒ»äººå¤´æ•°ï¼šX äººï¼ˆç²¾ç¡®è®¡æ•°ï¼‰ã€‚
                    ãƒ»æ€§åˆ«æ¯”ä¾‹ï¼šç”·æ€§ X äººï¼Œå¥³æ€§ Y äººï¼Œæ€§åˆ«ä¸æ˜ Z äººï¼ˆæ— äººç‰©åˆ™å¡« 0ï¼‰ã€‚
                    ãƒ»ç§æ—æ¯”ä¾‹ï¼šé»‘äººï¼Œç™½äººï¼Œäºšæ´²äººç­‰
                    ãƒ»å¹´é¾„æ®µï¼šæŒ‰å„¿ç«¥ï¼ˆï¼œ12 å²ï¼‰ã€é’å¹´ï¼ˆ12-35 å²ï¼‰ã€ä¸­å¹´ï¼ˆ36-60 å²ï¼‰ã€è€å¹´ï¼ˆï¼60 å²ï¼‰åˆ†ç±»ï¼Œæ ‡æ³¨å„å¹´é¾„æ®µäººæ•°ï¼ˆå¦‚ "é’å¹´ 2 äººï¼Œä¸­å¹´ 1 äºº"ï¼‰ã€‚
                    â–ªï¸ æ‰€åœ¨åœºæ™¯ï¼šå…·ä½“æè¿°ç¯å¢ƒï¼ˆå¦‚ "åŒ»é™¢å€™è¯ŠåŒº""æˆ·å¤–å…¬å›­""å®éªŒå®¤" ç­‰ï¼‰ï¼Œéœ€åŒ…å«å®¤å†… / å®¤å¤–ã€åœ°ç‚¹ç‰¹å¾ç­‰ç»†èŠ‚ã€‚
                    â–ªï¸ Sanofi ç›¸å…³æ€§ï¼šæ˜ç¡®è¯´æ˜æ˜¯å¦å‡ºç° Sanofi æ ‡å¿—ï¼ˆå¦‚ LOGOã€å“ç‰Œåç§°ï¼‰ã€äº§å“ï¼ˆå¦‚è¯å“åŒ…è£…ã€å®£ä¼ ææ–™ï¼‰ã€æ–‡å­—æåŠï¼ˆå¦‚ "Sanofi""èµ›è¯ºè²" å­—æ ·ï¼‰æˆ–ç›¸å…³åœºæ™¯ï¼ˆå¦‚ Sanofi æ´»åŠ¨ã€åˆä½œé¡¹ç›®ç­‰ï¼‰ï¼Œè‹¥æ— åˆ™æ ‡æ³¨ "æ— ç›¸å…³å…ƒç´ "ã€‚
                    ä½¿ç”¨è¯´æ˜ï¼š
                    è‹¥å›¾ç‰‡ä¸ºçº¯æ–‡å­—ï¼ˆå¦‚åˆåŒã€è¯´æ˜ä¹¦ï¼‰ï¼Œè¾“å‡ºä»…åŒ…å«æå–çš„æ–‡å­—å†…å®¹ã€‚
                    è‹¥å›¾ç‰‡ä¸ºéæ–‡å­—å†…å®¹ï¼ˆå¦‚ç…§ç‰‡ã€æ’ç”»ï¼‰ï¼ŒæŒ‰ä¸Šè¿°æ ¼å¼åˆ†ç‚¹è¯¦ç»†æè¿°ï¼Œäººç‰©ä¿¡æ¯éœ€ä¸¥æ ¼æŒ‰è¦æ±‚åˆ†ç±»ç»Ÿè®¡ã€‚
                    ç¡®ä¿è¯­è¨€ç®€æ´å‡†ç¡®ï¼Œé¿å…ä¸»è§‚æ¨æ–­ï¼Œä»…åŸºäºå›¾ç‰‡å¯è§å†…å®¹è¾“å‡ºã€‚
                    æ–°å¢éªŒè¯é¡¹
                    é’ˆå¯¹ä»¥ä¸‹åœºæ™¯ï¼Œæ˜ç¡®æ ‡æ³¨å·¥å…·æ˜¯å¦æ­£ç¡®è¯†åˆ«ï¼ˆéœ€åŸºäºå›¾ç‰‡å¯è§å†…å®¹åˆ¤æ–­ï¼Œè€Œéä¸»è§‚æ¨æµ‹ï¼‰ï¼š
                    å›¾ç‰‡é£æ ¼ï¼š æ˜¯å¦ä¸ºçœŸå®ç…§ç‰‡ï¼Œè¿˜æ˜¯æŸç§é£æ ¼å›¾åƒ
                    ç©ºåœºæ™¯è¯†åˆ«ï¼šå›¾ç‰‡æ˜¯å¦ä¸ºæ— äººã€æ— æ˜æ˜¾ç‰©ä½“çš„ç©ºåœºæ™¯ï¼ˆå¦‚ç©ºç™½å¢™é¢ã€çº¯è‰²èƒŒæ™¯ï¼‰ï¼Ÿ
                    â–¶ è¯†åˆ«ç»“æœï¼šæ˜¯ / å¦ / æ— æ³•åˆ¤æ–­ï¼ˆè‹¥æœ‰ç‰©ä½“æˆ–äººç‰©ï¼Œæ ‡æ³¨ "éç©ºåœºæ™¯"ï¼‰ã€‚
                    ä¼šè®®æ— å…³åœºæ™¯è¯†åˆ«ï¼šåœºæ™¯æ˜¯å¦ä¸ä¼šè®®æ— ç›´æ¥å…³è”ï¼ˆå¦‚çº¯è‡ªç„¶é£æ™¯ã€å•ç‹¬é™ç‰©ã€å¨±ä¹åœºæ‰€ç­‰ï¼‰ï¼Ÿ
                    â–¶ è¯†åˆ«ç»“æœï¼šæ˜¯ï¼ˆä¼šè®®æ— å…³ï¼‰/ å¦ï¼ˆå¯èƒ½ä¸ä¼šè®®ç›¸å…³ï¼‰/ æ— æ³•åˆ¤æ–­ã€‚
                    äººæ•°æ•æ‰ï¼šå·¥å…·æ˜¯å¦å‡†ç¡®ç»Ÿè®¡å›¾ç‰‡ä¸­çš„äººå¤´æ•°ï¼Ÿï¼ˆè‹¥æœ‰äººç‰©ï¼Œéœ€ä¸å®é™…è®¡æ•°ä¸€è‡´ï¼‰
                    â–¶ å®é™…äººå¤´æ•°ï¼šX äººï¼›å·¥å…·è¯†åˆ«ç»“æœï¼šX äººï¼ˆä¸€è‡´ / ä¸ä¸€è‡´ï¼‰ã€‚
                    ä¼šè®®è®¾å¤‡è¯†åˆ«ï¼šæ˜¯å¦æ­£ç¡®è¯†åˆ«ä¼šè®®å¿…è¦è®¾å¤‡ï¼ˆå¦‚æŠ•å½±ä»ªã€ç”µè„‘ã€éº¦å…‹é£ã€ç™½æ¿ã€ä¼šè®®æ¡Œç­‰ï¼‰ï¼Ÿ
                    â–¶ è¯†åˆ«è®¾å¤‡ï¼šè‹¥æœ‰ï¼Œåˆ—å‡ºå…·ä½“è®¾å¤‡åç§°ï¼ˆå¦‚ "æŠ•å½±ä»ªã€ç¬”è®°æœ¬ç”µè„‘"ï¼‰ï¼›è‹¥æ— ï¼Œæ ‡æ³¨ "æœªè¯†åˆ«åˆ°ä¼šè®®è®¾å¤‡"ã€‚
                    ä¼šè®®ç…§ç‰‡ç¿»æ‹è¯†åˆ«ï¼šå›¾ç‰‡æ˜¯å¦ä¸ºä¼šè®®ç…§ç‰‡çš„ç¿»æ‹ï¼ˆå¦‚å¯¹å±å¹•ã€çº¸è´¨ç…§ç‰‡çš„äºŒæ¬¡æ‹æ‘„ï¼Œå¯èƒ½å­˜åœ¨åå…‰ã€å˜å½¢ç­‰ç‰¹å¾ï¼‰ï¼Ÿ
                    â–¶ è¯†åˆ«ç»“æœï¼šæ˜¯ï¼ˆç¿»æ‹ç…§ç‰‡ï¼‰/ å¦ï¼ˆéç¿»æ‹ç…§ç‰‡ï¼‰/ æ— æ³•åˆ¤æ–­ã€‚
                    éæ­£å¸¸ä¼šè®®åœºæ‰€è¯†åˆ«ï¼šåœºæ™¯æ˜¯å¦ä¸ºéæ­£å¸¸ä¼šè®®åœºæ‰€ï¼ˆå¦‚å¨±ä¹åœºæ‰€ã€å¼€æ”¾åŒºåŸŸã€å®¶åº­ç¯å¢ƒç­‰ï¼‰ï¼Ÿ
                    â–¶ åœºæ‰€ç±»å‹ï¼šæ­£å¸¸ä¼šè®®åœºæ‰€ï¼ˆå¦‚ä¼šè®®å®¤ï¼‰/ éæ­£å¸¸ä¼šè®®åœºæ‰€ï¼ˆå…·ä½“æè¿°ï¼Œå¦‚ "KTV åŒ…å¢""å…¬å›­è‰åª"ï¼‰/ æ— æ³•åˆ¤æ–­ã€‚
                    å‚ä¼šäººéœ²è„¸è¯†åˆ«ï¼šæ˜¯å¦æ­£ç¡®è¯†åˆ«äººç‰©éœ²è„¸æƒ…å†µï¼ˆå…¨éƒ¨éœ²è„¸ / éƒ¨åˆ†æœªéœ²è„¸ / å…¨éƒ¨æœªéœ²è„¸ï¼‰ï¼Ÿ
                    â–¶ éœ²è„¸æƒ…å†µï¼šè‹¥æœ‰äººç‰©ï¼Œæ ‡æ³¨ "å…¨éƒ¨éœ²è„¸" æˆ– "X äººæœªéœ²è„¸"ï¼›æ— äººç‰©åˆ™æ ‡æ³¨ "æ— äººç‰©"ã€‚
                    éåˆè§„ç‰©ä»¶è¯†åˆ«ï¼šæ˜¯å¦å‡ºç°ä¸ä¼šè®®æ— å…³çš„éåˆè§„ç‰©ä»¶ï¼ˆå¦‚é…’ç“¶ã€éº»å°†æ¡Œã€é…’æ¯ï¼Œæ¸¸æˆæœºç­‰ï¼‰ï¼Œéœ€è¦ç€é‡æ£€æŸ¥ï¼Ÿ
                    â–¶ è¯†åˆ«ç»“æœï¼šæ˜¯ï¼ˆå…·ä½“ç‰©ä»¶ï¼šXXXï¼‰/ å¦ï¼ˆæ— éåˆè§„ç‰©ä»¶ï¼‰/ æ— æ³•åˆ¤æ–­ã€‚
                    '''
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        },
                        {
                            "type": "text",
                            "text": "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"
                        }
                    ]
                }
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Groqåˆ†æå‡ºé”™: {str(e)}"

# æ·»åŠ OpenAIå®¡æŸ¥æ€»ç»“å‡½æ•°
def summarize_with_openai(cv_results, groq_analysis, api_key):
    client = OpenAI(api_key=api_key,base_url="https://generativelanguage.googleapis.com/v1beta/")
    try:
        response = client.chat.completions.create(
            model="gemini-2.0-flash",
            messages=[
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„è¯å‚å®¡æŸ¥å…³å‘˜ã€‚è¯·æ ¹æ®CVæ£€æµ‹ç»“æœå’ŒAIåˆ†æç»“æœï¼Œç”Ÿæˆä¸€ä»½ç®€æ´çš„åˆè§„æ€§åˆ†ææŠ¥å‘Šã€‚
                    é‡ç‚¹å…³æ³¨ï¼š
                    0. æ˜¯å¦æœ‰sanofiçš„logoï¼Œæˆ–è€…æ˜ç¡®å’Œsanofiç›¸å…³çš„å› ç´ 
                    1. åœºæ™¯åˆè§„æ€§ï¼ˆæ˜¯å¦ä¸ºæ­£å¼ä¼šè®®åœºæ‰€ï¼‰
                    2. äººå‘˜æƒ…å†µï¼ˆäººæ•°ã€ç€è£…ã€è¡Œä¸ºæ˜¯å¦å¾—ä½“ï¼‰
                    3. ç‰©å“åˆè§„æ€§ï¼ˆæ˜¯å¦æœ‰è¿è§„ç‰©å“å¦‚é…’ç²¾é¥®å“ï¼‰
                    4. å›¾ç‰‡é£æ ¼æ˜¯å¦ä¸ºçœŸå®
                    5. æ•´ä½“è¯„ä¼°ï¼ˆæ˜¯å¦å»ºè®®é€šè¿‡å®¡æ ¸ï¼‰
                    è¯·ä»¥è¡¨æ ¼å½¢å¼è¾“å‡ºï¼Œå¯¹äºè¿è§„æƒ…å†µï¼ŒåŠ ç²—å­—ä½“ï¼Œä½¿ç”¨markdownæ ¼å¼ã€‚"""
                },
                {
                    "role": "user",
                    "content": f"CVæ£€æµ‹ç»“æœï¼š{cv_results}\n\nAIåˆ†æç»“æœï¼š{groq_analysis}"
                }
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"OpenAIæ€»ç»“å‡ºé”™: {str(e)}"

# ä¸»ç¨‹åº
try:
    # è·å–é€‰æ‹©çš„æ¨¡å‹åç§°
    selected_model = model_mapping[model_option]
    model = load_model(selected_model)
    
    # åŠ è½½äººè„¸æ£€æµ‹å™¨
    if detect_faces:
        face_detector = load_face_detector()
    
    # åŠ è½½ç‰¹å¾æå–æ¨¡å‹
    if enable_similarity_search or enable_face_similarity:
        feature_extractor = load_feature_extractor()
        transform = get_transform()
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    st.info(f"å½“å‰ä½¿ç”¨: {model_option}")
    
    # ä¿®æ”¹ä¸Šä¼ å›¾ç‰‡å¤„ç†éƒ¨åˆ†
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"], on_change=reset_processed_state)

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼ ä¸”å°šæœªå¤„ç†
    if uploaded_file is not None:
        # ä¸ºä¸Šä¼ æ–‡ä»¶ç”Ÿæˆå”¯ä¸€ID
        current_upload_id = id(uploaded_file)
        
        # æ˜¾ç¤ºåŸå§‹å›¾ç‰‡
        col1, col2 = st.columns(2)
        
        # å¦‚æœæ˜¯æ–°ä¸Šä¼ çš„æ–‡ä»¶æˆ–è€…å°šæœªå¤„ç†
        if current_upload_id != st.session_state.last_upload_id or not st.session_state.processed:
            # è¯»å–ä¸Šä¼ çš„å›¾ç‰‡
            image = Image.open(uploaded_file)
            st.session_state.image = image
            st.session_state.last_upload_id = current_upload_id
            
            with col1:
                st.subheader("åŸå§‹å›¾ç‰‡")
                st.image(image, use_container_width=True)
            
            # è¿›è¡Œç‰©ä½“æ£€æµ‹
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {model_option} è¿›è¡Œç‰©ä½“æ£€æµ‹..."):
                results = model.predict(image)
                st.session_state.detection_results = results
                
                # è·å–é€‰æ‹©çš„ç±»åˆ«
                selected_classes = []
                if detect_person:
                    selected_classes.append("äºº")
                if detect_cup:
                    selected_classes.append("æ¯å­/é…’æ¯")
                if detect_bottle:
                    selected_classes.append("ç“¶å­")
                if detect_all:
                    selected_classes.append("æ£€æµ‹æ‰€æœ‰æ”¯æŒçš„ç‰©ä½“")
                
                # å…ˆæ‰§è¡Œäººè„¸æ£€æµ‹ï¼ˆåœ¨åŸå§‹å›¾åƒä¸Šï¼‰
                detected_faces = []
                original_image_for_face = np.array(image)
                if detect_faces:
                    with st.spinner("æ­£åœ¨è¿›è¡Œäººè„¸æ£€æµ‹..."):
                        _, detected_faces = detect_face(original_image_for_face, face_detector, face_confidence)
                        st.session_state.detected_faces = detected_faces
                
                # å¤„ç†ç»“æœå¹¶æ ‡è®°ï¼ˆå…ˆç‰©ä½“æ£€æµ‹ï¼‰
                processed_img = process_prediction(image, results, selected_classes, confidence)
                st.session_state.processed_img = processed_img
                
                # å¦‚æœå¯ç”¨äº†äººè„¸æ£€æµ‹ï¼Œåœ¨ç‰©ä½“æ£€æµ‹ç»“æœä¸Šæ·»åŠ äººè„¸æ ‡è®°
                if detect_faces:
                    # è§£æäººè„¸è¾¹æ¡†é¢œè‰²
                    hex_color = face_box_color.lstrip('#')
                    face_bgr = tuple(int(hex_color[i:i+2], 16) for i in (4, 2, 0))  # è½¬æ¢ä¸ºBGR
                    
                    # å°†å¤„ç†è¿‡çš„å›¾åƒè½¬æ¢ä¸ºOpenCVæ ¼å¼
                    img_cv = cv2.cvtColor(np.array(processed_img), cv2.COLOR_RGB2BGR)
                    
                    # ä½¿ç”¨MTCNNæ£€æµ‹äººè„¸
                    faces = face_detector.detect_faces(original_image_for_face)
                    
                    # ç­›é€‰ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼çš„äººè„¸
                    faces = [face for face in faces if face['confidence'] >= face_confidence]
                    
                    # åœ¨å·²å¤„ç†çš„å›¾åƒä¸Šæ·»åŠ äººè„¸è¾¹æ¡†
                    for face in faces:
                        # è·å–è¾¹ç•Œæ¡†åæ ‡
                        x, y, w, h = face['box']
                        
                        # ç»˜åˆ¶äººè„¸è¾¹æ¡†
                        cv2.rectangle(img_cv, (x, y), (x+w, y+h), face_bgr, 2)
                        
                        # æ·»åŠ æ ‡ç­¾å’Œç½®ä¿¡åº¦
                        label = f"Face: {face['confidence']:.2f}"
                        cv2.putText(img_cv, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, face_bgr, 2)
                        
                        # å¯é€‰ï¼šç»˜åˆ¶å…³é”®ç‚¹
                        keypoints = face['keypoints']
                        for point in keypoints.values():
                            cv2.circle(img_cv, point, 2, face_bgr, 2)
                    
                    # è½¬æ¢å›RGB
                    processed_img = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB) 
                
                # å°†æœ€ç»ˆç»“æœä¿å­˜åˆ°session_state
                st.session_state.processed_img = processed_img
                
                # æ‰§è¡Œç›¸ä¼¼å›¾ç‰‡æœç´¢
                if enable_similarity_search or enable_face_similarity:
                    with st.spinner("æ­£åœ¨æ·»åŠ å›¾ç‰‡åˆ°å‘é‡åº“å¹¶æ‰§è¡Œç›¸ä¼¼æœç´¢..."):
                        # æå–ç‰¹å¾å¹¶æ›´æ–°å‘é‡åº“
                        image_id, face_ids = update_vector_db(image, detected_faces, feature_extractor, transform)
                        
                        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆè·å–æœ€æ–°çš„æ•°æ®ï¼‰
                        image_db, face_db = initialize_vector_db()
                        
                        # è·å–å½“å‰å›¾ç‰‡çš„ç‰¹å¾å‘é‡
                        current_image_vector = image_db[image_id]['vector']
                        
                        # æ‰§è¡Œç›¸ä¼¼å›¾ç‰‡æœç´¢
                        if enable_similarity_search:
                            # æ’é™¤å½“å‰å›¾ç‰‡
                            search_image_db = {k: v for k, v in image_db.items() if k != image_id}
                            similar_images = search_similar_images(
                                current_image_vector, 
                                search_image_db, 
                                top_k=top_k, 
                                threshold=similarity_threshold
                            )
                            
                            # ä¿å­˜æœç´¢ç»“æœåˆ°session_state
                            st.session_state.similar_images = similar_images
                        
                        # æ‰§è¡Œäººè„¸ç›¸ä¼¼æœç´¢
                        if enable_face_similarity and detected_faces:
                            # è·å–å½“å‰å›¾ç‰‡æ£€æµ‹åˆ°çš„äººè„¸ç‰¹å¾å‘é‡
                            current_face_vectors = []
                            for face_id in face_ids:
                                if face_id in face_db:
                                    current_face_vectors.append(face_db[face_id]['vector'])
                            
                            # æ’é™¤å½“å‰å›¾ç‰‡çš„äººè„¸
                            search_face_db = {k: v for k, v in face_db.items() if k not in face_ids}
                            
                            # å¯¹æ¯ä¸ªäººè„¸æ‰§è¡Œç›¸ä¼¼æœç´¢
                            similar_faces_results = search_similar_faces(
                                current_face_vectors, 
                                search_face_db, 
                                top_k=top_k, 
                                threshold=similarity_threshold
                            )
                            
                            # ä¿å­˜æœç´¢ç»“æœåˆ°session_state
                            st.session_state.similar_faces_results = similar_faces_results
                
                # æ ‡è®°ä¸ºå·²å¤„ç†
                st.session_state.processed = True
        else:
            # ä½¿ç”¨ä¹‹å‰å¤„ç†è¿‡çš„ç»“æœ
            image = st.session_state.image
            with col1:
                st.subheader("åŸå§‹å›¾ç‰‡")
                st.image(image, use_container_width=True)
        
        # æ˜¾ç¤ºå¤„ç†åçš„å›¾ç‰‡
        with col2:
            st.subheader("æ£€æµ‹ç»“æœ")
            st.image(st.session_state.processed_img, use_container_width=True)
        
        # æ˜¾ç¤ºç›¸ä¼¼å›¾ç‰‡æœç´¢ç»“æœ
        if enable_similarity_search and st.session_state.similar_images:
            display_similar_images(st.session_state.similar_images)
        
        # æ˜¾ç¤ºç›¸ä¼¼äººè„¸ç»“æœ
        if enable_face_similarity and st.session_state.similar_faces_results:
            display_similar_faces(st.session_state.similar_faces_results, st.session_state.detected_faces)
        
        # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„äººè„¸
        if detect_faces and st.session_state.detected_faces:
            st.subheader(f"æ£€æµ‹åˆ°çš„äººè„¸ä¸æƒ…ç»ªåˆ†æ ({len(st.session_state.detected_faces)})")
            face_cols = st.columns(min(len(st.session_state.detected_faces), 4))
            
            # æƒ…ç»ªå¯¹åº”çš„è¡¨æƒ…ç¬¦å·
            emotion_emojis = {
                "angry": "ğŸ˜ ",
                "disgust": "ğŸ¤¢",
                "fear": "ğŸ˜¨",
                "happy": "ğŸ˜Š",
                "sad": "ğŸ˜¢",
                "surprise": "ğŸ˜²",
                "neutral": "ğŸ˜"
            }
            
            for i, face in enumerate(st.session_state.detected_faces):
                with face_cols[i % 4]:
                    try:
                        # åˆ†æäººè„¸æƒ…ç»ª
                        result = DeepFace.analyze(face, actions=['emotion'], enforce_detection=False)
                        emotion = result[0]['dominant_emotion']
                        emotion_emoji = emotion_emojis.get(emotion, "")
                        
                        # æ˜¾ç¤ºäººè„¸å›¾åƒå’Œæƒ…ç»ª
                        st.image(face, caption=f"äººè„¸ #{i+1}")
                        st.write(f"ä¸»è¦æƒ…ç»ª: {emotion} {emotion_emoji}")
                        
                        # # æ˜¾ç¤ºæƒ…ç»ªåˆ†æ•°
                        # emotions = result[0]['emotion']
                        # # åˆ›å»ºæƒ…ç»ªåˆ†æ•°æ¡å½¢å›¾
                        # emotions_values = {k: v for k, v in emotions.items()}
                        # max_emotion = max(emotions_values, key=emotions_values.get)
                        # for emo, score in emotions_values.items():
                        #     emoji_icon = emotion_emojis.get(emo, "")
                        #     st.write(f"{emoji_icon} {emo}: {score:.2f}%")
                    except Exception as e:
                        st.error(f"åˆ†æäººè„¸ #{i+1} æ—¶å‡ºé”™: {str(e)}")
                        st.image(face, caption=f"äººè„¸ #{i+1} (æƒ…ç»ªåˆ†æå¤±è´¥)")
        elif detect_faces and not st.session_state.detected_faces:
            st.info("æœªæ£€æµ‹åˆ°äººè„¸")
        
        # æ·»åŠ ä¸‹è½½æŒ‰é’®
        buf = io.BytesIO()
        pil_img = Image.fromarray(st.session_state.processed_img)
        pil_img.save(buf, format="PNG")
        st.download_button(
            label="ä¸‹è½½æ£€æµ‹ç»“æœ",
            data=buf.getvalue(),
            file_name="detected_image.png",
            mime="image/png",
        )
        
        # æ˜¾ç¤ºæ£€æµ‹ç»Ÿè®¡ä¿¡æ¯
        if results[0].boxes is not None:
            # è·å–æ‰€æœ‰æ£€æµ‹ç»“æœçš„ç±»åˆ«
            all_classes = results[0].boxes.cls.cpu().numpy()
            all_confidences = results[0].boxes.conf.cpu().numpy()
            
            # ç»Ÿè®¡æ£€æµ‹åˆ°çš„ç‰©ä½“æ•°é‡
            st.subheader("æ£€æµ‹ç»Ÿè®¡")
            class_names = results[0].names
            
            # åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œç”¨äºå­˜å‚¨å„ç±»åˆ«çš„è®¡æ•°
            class_counts = {}
            
            for cls, conf in zip(all_classes, all_confidences):
                cls_id = int(cls)
                # å¦‚æœç±»åˆ«åœ¨é€‰ä¸­çš„ç±»åˆ«ä¸­ä¸”ç½®ä¿¡åº¦é«˜äºé˜ˆå€¼
                if ((cls_id == 0 and "äºº" in selected_classes) or
                    (cls_id == 41 and "æ¯å­/é…’æ¯" in selected_classes) or
                    (cls_id == 39 and "ç“¶å­" in selected_classes) or
                    detect_all) and conf >= confidence:
                    
                    cls_name = class_names[cls_id]
                    if cls_name in class_counts:
                        class_counts[cls_name] += 1
                    else:
                        class_counts[cls_name] = 1
            
            # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
            for cls_name, count in class_counts.items():
                st.write(f"- æ£€æµ‹åˆ° {count} ä¸ª {cls_name}")
            
            # æ·»åŠ äººè„¸è®¡æ•°åˆ°ç»Ÿè®¡ç»“æœ
            if detect_faces and st.session_state.detected_faces:
                st.write(f"- æ£€æµ‹åˆ° {len(st.session_state.detected_faces)} ä¸ªäººè„¸")
            
            if not class_counts and not (detect_faces and st.session_state.detected_faces):
                st.write("æœªæ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“")

            # æ·»åŠ AIåˆ†æéƒ¨åˆ†
            st.subheader("AIç»¼åˆåˆ†æ")
            
            with st.spinner("æ­£åœ¨è¿›è¡ŒAIåˆ†æ..."):
                # è·å–API keys
                groq_api_key = os.environ.get("GROQ_API_KEY")
                openai_api_key = os.environ.get("GEMINI_API_KEY")
                
                if groq_api_key and openai_api_key:
                    # æ‰§è¡ŒGroqåˆ†æ
                    groq_analysis = analyze_with_groq(image, groq_api_key)
                    print(groq_analysis)
                    # å‡†å¤‡CVæ£€æµ‹ç»“æœæ‘˜è¦
                    cv_summary = {
                        "detected_objects": class_counts,
                        "face_count": len(st.session_state.detected_faces) if detect_faces else 0
                    }
                    
                    # æ‰§è¡ŒOpenAIæ€»ç»“
                    final_summary = summarize_with_openai(cv_summary, groq_analysis, openai_api_key)
                    
                    # æ˜¾ç¤ºåˆ†æç»“æœ
                    st.markdown(final_summary)
                else:
                    st.warning("è¯·è®¾ç½®GROQ_API_KEYå’ŒOPENAI_API_KEYç¯å¢ƒå˜é‡ä»¥å¯ç”¨AIåˆ†æåŠŸèƒ½")

except Exception as e:
    st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
    if "æœªèƒ½ä¸‹è½½é¢„è®­ç»ƒæƒé‡" in str(e) or "Failed to download" in str(e):
        st.warning(f"é¦–æ¬¡è¿è¡Œæ—¶éœ€è¦ä¸‹è½½YOLOv8æ¨¡å‹ï¼Œè¯·ç¡®ä¿æ‚¨æœ‰ç¨³å®šçš„ç½‘ç»œè¿æ¥ã€‚è¾ƒå¤§çš„æ¨¡å‹ä¸‹è½½å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ã€‚")
    
# æ·»åŠ ä½¿ç”¨è¯´æ˜
with st.expander("ä½¿ç”¨è¯´æ˜"):
    st.markdown("""
    ### ä½¿ç”¨æ–¹æ³•ï¼š
    1. ä¸Šä¼ ä¸€å¼ åŒ…å«è¦æ£€æµ‹ç‰©ä½“çš„å›¾ç‰‡
    2. åœ¨ä¾§è¾¹æ è°ƒæ•´æ£€æµ‹è®¾ç½®ï¼š
       - é€‰æ‹©æ¨¡å‹ï¼ˆç²¾åº¦ä¸é€Ÿåº¦çš„å¹³è¡¡ï¼‰
       - è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆå€¼è¶Šé«˜ï¼Œè¯¯æ£€æµ‹è¶Šå°‘ï¼Œä½†ä¹Ÿå¯èƒ½æ¼æ‰ä¸€äº›ç‰©ä½“ï¼‰
       - é€‰æ‹©è¦æ£€æµ‹çš„ç‰©ä½“ç±»åˆ«
       - å¯ç”¨/ç¦ç”¨äººè„¸æ£€æµ‹
       - è®¾ç½®ç›¸ä¼¼å›¾ç‰‡å’Œäººè„¸æœç´¢é€‰é¡¹
       - è‡ªå®šä¹‰æ ‡è®°é¢œè‰²
    3. æŸ¥çœ‹æ£€æµ‹ç»“æœã€ç›¸ä¼¼å›¾ç‰‡æœç´¢ç»“æœï¼Œå¹¶ä¸‹è½½æ ‡è®°åçš„å›¾ç‰‡
    
    ### æ¨¡å‹æ¯”è¾ƒï¼š
    - YOLOv8x: æœ€é«˜ç²¾åº¦ï¼Œä½†å¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œé€‚åˆå¯¹ç²¾åº¦è¦æ±‚é«˜çš„åœºæ™¯
    - YOLOv8l: é«˜ç²¾åº¦ï¼Œé€Ÿåº¦é€‚ä¸­
    - YOLOv8m: å¹³è¡¡çš„ç²¾åº¦å’Œé€Ÿåº¦
    - YOLOv8s: è¾ƒå¿«çš„é€Ÿåº¦ï¼Œç²¾åº¦é€‚ä¸­
    - YOLOv8n: æœ€å¿«çš„é€Ÿåº¦ï¼Œä½†ç²¾åº¦è¾ƒä½
    
    ### ç›¸ä¼¼å›¾ç‰‡å’Œäººè„¸æœç´¢ï¼š
    - ç³»ç»Ÿä¼šå°†æ¯æ¬¡ä¸Šä¼ çš„å›¾ç‰‡æ·»åŠ åˆ°å‘é‡æ•°æ®åº“ä¸­
    - ç›¸ä¼¼å›¾ç‰‡æœç´¢ï¼šæŸ¥æ‰¾ä¸ä¸Šä¼ å›¾ç‰‡è§†è§‰ç‰¹å¾ç›¸ä¼¼çš„å†å²å›¾ç‰‡
    - äººè„¸ç›¸ä¼¼æœç´¢ï¼šå¯¹æ£€æµ‹åˆ°çš„æ¯ä¸ªäººè„¸ï¼ŒæŸ¥æ‰¾æ•°æ®åº“ä¸­ç›¸ä¼¼çš„äººè„¸
    - å¯è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼å’Œè¿”å›ç»“æœæ•°é‡
    
    ### æ”¯æŒæ£€æµ‹çš„ç‰©ä½“ï¼š
    - äººç‰©
    - æ¯å­/é…’æ¯
    - ç“¶å­
    - äººè„¸ï¼ˆä½¿ç”¨OpenCVçš„äººè„¸æ£€æµ‹å™¨ï¼‰
    """)

# æ·»åŠ é¡µè„š
st.markdown("---")
st.markdown("ğŸ“¸ é«˜ç²¾åº¦ç‰©ä½“æ£€æµ‹å·¥å…· | åŸºäºYOLOv8å’ŒStreamlitæ„å»º")


###
